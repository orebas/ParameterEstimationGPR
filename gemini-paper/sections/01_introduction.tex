\section{Introduction}
\label{sec:introduction}

Parameter estimation for ordinary differential equation (ODE) models is a fundamental challenge in nearly every scientific and engineering discipline. While ODEs provide a powerful language for describing the dynamics of physical, biological, and economic systems, their utility often hinges on determining the correct values for unknown parameters from experimental data. The dominant paradigm for this task relies on nonlinear optimization, often called a "shooting" or "simulation-based" approach. These methods iteratively guess parameter values, simulate the ODE, and adjust the guess to minimize the discrepancy between the simulation and the observed data.

While widely adopted, this optimization-based framework suffers from well-known practical limitations. Its performance is often highly sensitive to the initial parameter guesses, a value that is rarely known \textit{a priori}. Consequently, these methods are susceptible to converging to local, non-optimal minima in the error landscape, potentially yielding incorrect parameter estimates. Furthermore, they are designed to find only a single set of optimal parameters, which is a significant drawback for systems that are only locally identifiable and may possess multiple, distinct parameter sets that explain the data equally well.

An alternative, the differential-algebraic approach, offers a compelling solution to these problems. By transforming the ODE system into a set of algebraic equations, this method eliminates the need for initial guesses and can, in principle, recover all valid parameter sets. This makes it a powerful tool for robust parameter estimation and for exploring the full landscape of system identifiability. However, the practical adoption of algebraic methods has been severely hampered by a critical flaw: an extreme sensitivity to measurement noise. The method relies on computing high-order derivatives of the observed data, a process that catastrophically amplifies even minuscule amounts of noise. This has relegated the algebraic approach to a theoretical curiosity, largely unusable for the noisy data characteristic of real-world experiments.

This paper bridges the gap between the theoretical promise of algebraic methods and the practical demands of real-world data. We introduce a novel approach that replaces the fragile derivative estimation step of the classic algebraic method with a robust, probabilistic smoother: Gaussian Process Regression (GPR). We demonstrate that this GPR-enhanced algebraic method preserves the key advantages of the original approach---no initial guesses, recovery of all solutions---while achieving a level of robustness to noise that makes it competitive with, and in some cases superior to, traditional optimization-based techniques.

Through a comprehensive benchmark on a diverse suite of 11 dynamical systems, we show that our method successfully estimates parameters in noise regimes where the original algebraic approach fails completely. This work demonstrates that by addressing the critical bottleneck of derivative estimation, we can finally make algebraic parameter estimation a practical, robust, and powerful tool for the modern scientist and engineer.
