% This is a flattened version of the paper for easier LLM parsing.
% All \input and \include commands have been recursively expanded.
% Figures, tables, and code blocks have been removed or simplified.
% Generated by python/flatten_tex.py
%
% Benchmark Study: Derivative Estimation Methods
% Template for SIAM SISC or ACM TOMS submission
\documentclass[11pt]{article}

% Essential packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}  % For tables that span multiple pages
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{placeins}  % Provides \FloatBarrier for better float control

% Code listings
\usepackage{listings}
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
}

% TODO handling - visible but doesn't break compilation
\newcommand{\TODO}[1]{\textcolor{red}{\textbf{[TODO: #1]}}}
\newcommand{\TODOITEM}{\textcolor{red}{$\blacksquare$~}}

% Math operators
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

% Figure path - points to build directory (generated by scripts/03_generate_figures.sh)
}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
}

% Title and authors
\title{Benchmark Study of Derivative Estimation Methods:\\
Performance Across Orders and Noise Levels}

\author{
    Oren Bassik\thanks{CUNY Graduate Center, Department of Mathematics, obassik@gradcenter.cuny.edu}
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Derivative estimation from noisy data is a fundamental problem across computational science, yet systematic comparative evaluation of methods remains lacking. We present a comprehensive benchmark of 28 derivative estimation methods tested across derivative orders 0--7 (with primary analysis focusing on orders 0--5 for fair comparison), 7 noise levels, and 3 distinct dynamical systems. Our goal is to provide clear, actionable guidance for practitioners.

Key findings include: (1) Gaussian Process Regression (GPR) provides the most robust and accurate performance, consistently ranking as the top method in both low- and high-noise regimes. (2) The optimal method depends critically on the use case: splines like Dierckx-5 are highly competitive for low-noise data, while spectral methods offer a compelling balance of speed and accuracy, and filters like Savitzky-Golay provide a robust, computationally cheap baseline. (3) Derivative order is the dominant difficulty factor, with performance degrading systematically as order increases. We also provide a practitioner's guide to method selection based on the trade-off between speed and accuracy. Our full methodology, analysis, and code are provided to ensure transparency and reproducibility.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
% NEW PAPER STRUCTURE
%==============================================================================


% ===== BEGIN INCLUDED FILE: sections/section1_introduction =====
\section{Introduction}
\label{sec:introduction}

Derivative estimation from noisy data is a fundamental and notoriously ill-posed problem spanning computational science, engineering, and data analysis. Small noise perturbations in the input signal can produce arbitrarily large errors in derivative estimates, a challenge that intensifies rapidly with the derivative order. Despite this, reliable derivatives are essential in many settings, including:

\begin{itemize}
    \item \textbf{Dynamical Systems Identification:} Inferring governing equations from time-series or field data requires accurate derivative estimates to identify differential equations~\cite{Brunton_etal_2016}.
    \item \textbf{Signal Processing:} Edge detection, feature extraction, and change-point analysis all depend on robust derivative computation.
    \item \textbf{Control Systems:} Model-predictive and adaptive control rely on real-time derivative estimation for system state feedback.
    \item \textbf{Physics-Informed Machine Learning:} Enforcing physical conservation laws (PDE constraints) requires differentiating neural network outputs with respect to noisy inputs~\cite{Raissi_etal_2019}.
    \item \textbf{Scientific Data Analysis:} Estimating rates of change from experimental measurements, such as reaction rates from concentration data or acceleration from position measurements.
\end{itemize}

Our investigation is motivated by the challenges of parameter estimation in ordinary differential equations (ODEs), where accurate derivative estimates are crucial. ODEs provide an ideal testbed for differentiation methods: the structure of an ODE system, $\dot{\mathbf{x}} = f(\mathbf{x})$, provides a natural source of high-precision ground-truth data. Higher-order derivatives can be generated by repeatedly differentiating the system's equations, e.g., $\ddot{\mathbf{x}} = \frac{\partial f}{\partial \mathbf{x}} \dot{\mathbf{x}}$. This process, performed symbolically or via system augmentation, allows for the creation of a validation dataset without resorting to a separate numerical differentiation method, thus avoiding circularity. Our previous work demonstrated the potential of certain methods, such as the AAA algorithm~\cite{Nakatsukasa_etal_2018} with automatic differentiation, for differentiating noiseless data from dynamical systems~\cite{Bassik_etal_2023}.

Despite the importance of this problem, systematic comparative evaluation of numerical differentiation methods is conspicuously absent from the literature~\cite{Listmann_etal_2013, Knowles_2009, Walker_1988}. Existing studies suffer from several limitations:
\begin{enumerate}
    \item \textbf{Limited Scope:} They typically evaluate only a handful of methods on low-order derivatives (first or second), neglecting high-order derivatives where performance diverges dramatically (e.g.,~\cite{Listmann_etal_2013, Knowles_2009}).
    \item \textbf{Single-Noise Regime:} They test either noiseless or high-noise cases, missing crucial performance transitions across noise levels.
    \item \textbf{Incomplete Coverage Transparency:} Methods that fail at high orders or under high noise are often excluded without clear documentation, obscuring practical limits.
\end{enumerate}

To address this gap, the present study provides a comprehensive, transparent, and reproducible benchmark of numerical differentiation methods. We employ a systematic elimination process, starting from a broad set of hypotheses and progressively refining our analysis to arrive at specific, actionable recommendations. Our evaluation is conducted across three distinct dynamical systems and a wide spectrum of noise levels, ensuring the robustness and generalizability of our findings. The primary contribution of this work is therefore not merely to rank methods, but to provide the reader with a deeper understanding of the principles that govern their success and failure in different scenarios, ultimately equipping them with clear guidance for their own data analysis challenges.

\textbf{The main contributions of this paper are:}
\begin{itemize}
    \item A comprehensive benchmark of 28 numerical differentiation methods tested across derivative orders 0-7 (primary analysis on orders 1-5), seven noise levels (from $10^{-8}$ to 2\%), and three dynamical systems
    \item Identification of the composable ``Approximant-AD'' framework as a key pattern for success, combining smooth function fitting with automatic differentiation
    \item Demonstration that Gaussian Process regression with Taylor-mode AD provides the most robust performance across all conditions
    \item A practical three-tier framework for method selection based on speed-accuracy trade-offs
    \item Complete reproducible code, data, and analysis pipeline to support future research and practitioner adoption
\end{itemize}

% ===== END INCLUDED FILE: sections/section1_introduction =====

\FloatBarrier

% ===== BEGIN INCLUDED FILE: sections/section2_related_work =====
\section{Related Work}
\label{sec:related_work}

The estimation of derivatives from discrete, noisy data is a classical and notoriously ill-posed inverse problem. The core challenge lies in the nature of differentiation as a high-pass operator, which unavoidably amplifies high-frequency components, including measurement noise. Small perturbations in the input signal can thus lead to arbitrarily large errors in the derivative estimates, a problem that intensifies rapidly with each successive derivative order.  

Despite this difficulty, robust derivative estimates are essential prerequisites for a vast array of scientific and engineering applications. In systems biology and physics, they form the basis for identifying governing equations from time-series data, a cornerstone of dynamical systems identification. Seminal methods in this area, such as the sparse identification of nonlinear dynamics (SINDy) framework, explicitly depend on accurate derivative data to build sparse regression models. In modern machine learning, the enforcement of physical laws within neural network models (e.g., Physics-Informed Neural Networks or PINNs) requires differentiating network outputs, often with respect to noisy or sparse inputs. Similar requirements are found in control systems, signal processing, and experimental data analysis.  

Given the problem's ubiquity, a wide variety of algorithmic solutions have been proposed. However, as noted in the introduction, systematic, broad-scope comparative evaluation of these methods is conspicuously absent from the literature.  

\subsection{Review of Prior Comparative Studies}

Existing comparative studies on numerical differentiation are few and are typically limited in scope, either by the number of methods tested or, more critically, by their focus on low-order (first or second) derivatives.

For example, Listmann, Kugi, and Böhm~\cite{Listmann_etal_2013} presented a comparison of methods specifically for higher-order derivatives, a focus that aligns with the present study. However, their comparison was narrow, evaluating only three distinct methods (a B-spline-based approach, an integration-based method, and a sliding-mode-based differentiator) with a specific focus on industrial automation and control applications.  

A broader comparative study by Knowles~\cite{Knowles_2009} evaluated six different algorithmic families for differentiating noisy data: least-squares polynomial approximation, Tikhonov regularization, smoothing splines, convolution smoothing, a variational method, and total variation regularization. While comprehensive in its methodological breadth, this study's evaluation was explicitly limited to the first derivative ($k=1$), and its primary conclusion---that Tikhonov regularization performed best on dense data---provides little guidance for the high-order ($k \geq 3$) regimes explored in our work.  

Other comparisons are often highly domain-specific, such as Walker's simulation experiment comparing algorithms for estimating velocity and acceleration (first and second derivatives) from animal locomotion data. These studies, while valuable in their respective fields, do not provide the general-purpose, high-order, and broad-method benchmark required by the wider scientific computing community. They fail to capture the dramatic performance degradation and divergence of methods at higher derivative orders ($k \geq 3$), a primary focus of the present investigation.  

\subsection{Foundational Methodologies: A Thematic Review}
\label{sec:foundational_methodologies}

The 28 methods evaluated in this benchmark are drawn from several distinct, mature sub-fields of numerical analysis and machine learning. The following review outlines the foundational literature for each major method category.  

\subsubsection{Local Polynomial and Filtering Methods}

The most well-known method in this category is the Savitzky-Golay filter, introduced in a seminal 1964 paper. This filter is fundamentally a local least-squares polynomial approximation. For each data point, a polynomial of a given degree is fitted to a symmetric window of neighboring points, and the value of the smoothed function (or its derivative) at that point is taken from the fitted polynomial. Savitzky and Golay demonstrated that this process is equivalent to a discrete convolution with a fixed set of pre-computed coefficients, making it exceptionally computationally efficient (O(n)). Its enduring popularity stems from its ability to preserve signal features like peak height and width more effectively than simple moving-average filters, and its coefficients can be modified to compute derivatives directly. The several Savitzky-Golay variants tested in this study are modern implementations of this 60-year-old technique.  

\subsubsection{Spline-Based Methods}

Spline-based methods approximate the underlying function by fitting a piecewise-polynomial function (the spline) to the data. A key challenge is the trade-off between fidelity to the noisy data and the smoothness of the resulting approximant. This is exemplified by the FORTRAN library FITPACK, which forms the basis for the Spline-Dierckx-5 method evaluated in this benchmark. FITPACK uses a smoothing parameter to balance this trade-off, often requiring user tuning.  

The theory of generalized smoothing splines, introduced by Grace Wahba and others, provides a more formal, statistical framework for this problem. In this framework, the approximant is found by minimizing a cost function that combines a data-fidelity term (e.g., sum-of-squares error) with a regularization term (e.g., the integrated squared second derivative). This approach provides a principled method for selecting the smoothing parameter automatically, most notably via Generalized Cross-Validation (GCV). Several methods in our benchmark leverage GCV for hyperparameter selection (e.g., Fourier-GCV).  

\subsubsection{Global Basis Function Methods}

In contrast to local methods, global methods fit a single function over the entire domain. Spectral methods are the most prominent example, approximating the function as a sum of global basis functions, such as a truncated Fourier series or a Chebyshev polynomial expansion. The foundational text by Gottlieb and Orszag~\cite{Gottlieb_Orszag_1977} established the theory for these methods, demonstrating their "spectral accuracy" (i.e., exponential convergence) for smooth, analytic functions. Differentiation is trivial in this basis: for a Fourier series, it is a simple multiplication in the frequency domain, providing an efficient $O(n\log n)$ algorithm.  

Rational approximation, which models the function as a ratio of two polynomials, is another powerful global method. The Adaptive Antoulas-Anderson (AAA) algorithm, introduced by Nakatsukasa, Sète, and Trefethen, has emerged as a robust and efficient method for finding near-best rational approximants in a greedy, adaptive manner~\cite{Nakatsukasa_etal_2018}. As noted in our introduction, this method is exceptionally powerful for approximating data from dynamical systems in noise-free contexts. A key finding of the present study, however, is that this state-of-the-art performance does not transfer to noisy signals, where the AAA algorithm's greedy selection process demonstrates significant instability.  

\subsubsection{Regularization-Based Methods}

These methods reframe differentiation as an ill-posed inverse problem to be solved via regularization. Tikhonov regularization is a common approach~\cite{Knowles_2009}. An alternative, Total Variation (TV) regularization, was proposed for numerical differentiation by Chartrand~\cite{Chartrand_2011}. This method is notable because it uses an $L_1$ norm on the derivative, a choice that "allows for discontinuous solutions". TV-regularized differentiation is therefore highly effective for signals with jumps or sharp corners, as it can accurately locate these discontinuities without the "ringing" (Gibbs phenomenon) characteristic of spectral methods. However, the dynamical systems used as testbeds in this study (Lotka-Volterra, Lorenz, etc.) are smooth. The inclusion of TVRegDiff-Python in our benchmark thus serves as an important test of methodological suitability, illustrating the "impedance mismatch" of applying a method designed for non-smooth problems to a smooth one.  

\subsubsection{Probabilistic (Kernel) Methods}

This category, which includes the top-performing methods in our benchmark, is dominated by Gaussian Process Regression (GPR). As detailed in the canonical text by Rasmussen and Williams, GPR is a non-parametric Bayesian method that provides a principled, probabilistic approach to learning in kernel machines. Rather than fitting a specific functional form, GPR places a prior distribution over the space of functions itself. When applied to regression, GPR computes a posterior distribution over functions that pass near the noisy data points. The posterior mean function serves as an optimal "approximant" that naturally balances data-fit with smoothness, as defined by a chosen kernel (e.g., the RBF kernel). This makes GPR an exceptionally powerful and robust smoother, and, as our study finds, an ideal candidate for the first step of a derivative estimation pipeline.  

\subsection{From Monolithic Algorithms to Composable Frameworks}

The review above highlights a crucial trend: the maturation of the field from monolithic, single-purpose algorithms (e.g., a "Savitzky-Golay 2nd-derivative algorithm") to a composable, two-step "Approximant-AD" framework. This modern paradigm, which is a core finding of our study, decouples the problem:  

\begin{enumerate}
    \item \textbf{Fit an Approximant:} A smooth, analytic function is fitted to the noisy data using one of the mature methodologies described in Section 2.2 (e.g., GPR, Splines, etc.).
    \item \textbf{Differentiate via AD:} This analytic function is then differentiated to machine precision using Automatic Differentiation (AD).
\end{enumerate}

This composable pattern allows practitioners to leverage the vast ecosystems of both statistical modeling and AD, as detailed in surveys like Baydin et al.~\cite{Baydin_etal_2018}. However, our benchmark reveals a critical, and previously un-benchmarked, bottleneck in this framework.  

\subsubsection{Taylor-Mode AD: The Enabling Technology for High Orders}

While AD provides exact derivatives of a function, the computational cost of computing high-order derivatives is a critical, and often prohibitive, factor. Naively computing a $k$-th order derivative by recursively composing a first-order AD operator $k$ times results in exponential computational complexity in $k$. This renders the computation of 5th, 6th, or 7th-order derivatives practically infeasible.  

A far more efficient, though less common, alternative is Taylor-mode automatic differentiation. As described by Frost, Johnson, and Meles~\cite{Frost_etal_2021} in the context of the JAX library, Taylor-mode AD avoids this exponential cost by propagating a full Taylor series expansion (i.e., all derivative coefficients up to order $k$) through the computational graph in a single forward pass. This reduces the computational complexity from exponential to polynomial. Julia-based packages like TaylorDiff.jl implement this approach, offering "linear scaling with the order of differentiation".  

As our results demonstrate, this is not merely an optimization but an enabling technology. The superior performance of our top-ranked method, GP-TaylorAD-Julia, is critically dependent on this fusion: it combines the best-in-class approximant (GPR) with the only efficient AD method for high orders (Taylor-mode). This study, therefore, provides strong empirical evidence that modern AD techniques are a necessary component for solving the classical problem of high-order derivative estimation from noisy data.  

\subsection{Positioning the Present Study}

The existing literature on numerical differentiation consists of fragmented, small-scale comparisons focused on low-order derivatives~\cite{Listmann_etal_2013, Knowles_2009}, and foundational work on individual method families. A large-scale, systematic benchmark evaluating these methods in concert, particularly in the challenging high-order regime ($k>3$), has been a conspicuous gap.

The present study addresses this gap by (1) providing a comprehensive benchmark of 28 methods across orders 0-7, (2) identifying the composable "Approximant-AD" framework as the key pattern for success, and (3) providing the first empirical demonstration that the fusion of Gaussian Process regression with Taylor-mode AD is the most robust and accurate solution to this long-standing problem.

% ===== END INCLUDED FILE: sections/section2_related_work =====

\FloatBarrier

% ===== BEGIN INCLUDED FILE: sections/section3_methods =====
\section{Methodology and Implementation}
\label{sec:methods}

The derivative estimation methods evaluated in this study were selected through a systematic survey and filtering process designed to cover a broad range of algorithmic approaches. The foundational background for the method families considered in this work—including local polynomial filters, splines, global basis functions, regularization, and probabilistic methods—is detailed in Section~\ref{sec:foundational_methodologies}.

This section details the specific criteria for method selection, key implementation choices for computing high-order derivatives, and the precise implementation of our top-performing Gaussian Process Regression approach.

\subsection{Systematic Filtering and Final Selection}
\label{sec:filtering_criteria}

From the initial survey, a rigorous multi-stage filtering process was applied to identify methods suitable for benchmarking:

\textbf{Stage 1: Stability Assessment.} Methods were first evaluated for numerical stability on noisy data. For example, the Adaptive Antoulas-Anderson (AAA) algorithm, while exceptionally powerful for rational approximation in noise-free contexts~\cite{Nakatsukasa_etal_2018, Bassik_etal_2023} (and our preferred interpolation method in that context), demonstrated significant instability when applied to noisy signals. The resulting derivative estimates frequently contained errors several orders of magnitude larger than other methods. The least stable methods were excluded from further analysis.


\textbf{Stage 2: Coverage Requirement.} We initially planned to require packages to support arbitrary derivative orders. In practice, orders $6$–$7$ (and often $5$) are both rarer in applications and substantially more fragile. Accordingly, our \emph{primary ranking} requires methods to produce valid derivatives for orders $0$–$5$ (across all systems and noise levels). Methods with narrower scope—whether due to theoretical limits (e.g., low-degree local polynomials) or implementation constraints—are documented but omitted from the primary comparison. Orders $6$–$7$ are reported separately as a stress test (Appendix~X). This criterion preserves a like-for-like comparison among methods with comparable capabilities.

\textbf{Stage 3: Implementation Verification.} Each remaining method was verified to produce valid output across all test configurations (three dynamical systems, seven noise levels). Methods that failed consistently on specific systems or noise regimes were excluded.

This systematic filtering yielded a final cohort of 28 methods that demonstrated both numerical stability and complete coverage for orders 0--5, forming the basis for the comparative analysis presented in Section~\ref{sec:results}. Methods are implemented in both Python and Julia, spanning the algorithmic families described above: Gaussian Process methods, spline interpolation, spectral approaches, filtering techniques, and Total Variation regularization.

\subsection{Implementation Considerations for High-Order Derivatives}
\label{sec:implementation_challenges}

A significant practical challenge in benchmarking derivative estimation methods is the computation of arbitrarily high-order derivatives, as most existing packages support only first or second derivatives. Three complementary approaches were employed in this study to address this limitation:

\begin{itemize}
    \item \textbf{Augmentation with Automatic Differentiation:} For methods whose underlying approximant was differentiable (e.g., Gaussian Processes), implementations were augmented with AD capabilities. Our Julia implementation leverages Taylor-mode AD~\cite{TaylorDiff_jl} for efficient computation of high-order derivatives.
    
    \item \textbf{Analytic Derivative Computation:} For methods such as splines or Fourier series, analytic expressions for higher-order derivatives were derived and implemented directly. This approach provides exact derivatives of the approximant function while maintaining computational efficiency.
    
    \item \textbf{Noise Estimation Integration:} Several methods require noise level estimates as hyperparameters. Where not provided by the original implementation, noise estimation routines based on wavelet MAD (Median Absolute Deviation)~\cite{Donoho_Johnstone_1994} or simple finite-difference variance estimation~\cite{Gasser_etal_1986} were integrated.
\end{itemize}

These implementation enhancements ensured a level playing field for comparison while maintaining the essential characteristics of each method.

\subsection{Gaussian Process Regression Implementation}
\label{sec:gpr_implementation}

Given the exceptional performance of Gaussian Process methods in our results, we provide specific implementation details for reproducibility. Our GPR approach~\cite{Fairbrother_etal_2022} follows a standard but carefully optimized workflow:

\begin{enumerate}
    \item \textbf{Kernel Selection:} We employ the squared exponential (RBF) kernel~\cite{Rasmussen_Williams_2006}: $k(x, x') = \sigma^2_f \exp(-\|x - x'\|^2 / 2\ell^2)$, where $\ell$ is the length scale and $\sigma_f$ is the signal variance.

    \item \textbf{Hyperparameter Optimization:} The hyperparameters $(\ell, \sigma_f, \sigma_n)$ are optimized via maximum likelihood estimation using L-BFGS-B optimization~\cite{Byrd_etal_1995} on the log marginal likelihood.

    \item \textbf{Derivative Computation:} Rather than using kernel derivatives, we extract the posterior mean function and differentiate it directly using automatic differentiation. This approach provides exact derivatives of the smooth interpolant.

    \item \textbf{Taylor-mode AD:} The Julia implementation leverages Taylor-mode automatic differentiation~\cite{TaylorDiff_jl} for efficient computation of derivatives up to order 7 in a single forward pass. Python implementations lack this capability, explaining their 10× slower performance.
\end{enumerate}

This ``fit-then-differentiate'' approach treats GPR as a sophisticated smoothing method, discarding the uncertainty quantification machinery after fitting to focus solely on the mean prediction and its derivatives.

% Method catalog removed - 31 tested methods are listed in results section and detailed in Appendix A
% ===== END INCLUDED FILE: sections/section3_methods =====

\FloatBarrier

% ===== BEGIN INCLUDED FILE: sections/section4_design =====
\section{Experimental Design}
\label{sec:design}

To create a robust and comprehensive benchmark, we first formally define the estimation problem.

\subsection{Formal Problem Statement}
\label{sec:problem_statement}

\begin{description}
    \item[Given:]
    \begin{itemize}
        \item A smooth but analytically unknown function $f: \mathbb{R} \to \mathbb{R}$.
        \item A set of $n$ noisy observations $\{(t_i, y_i)\}_{i=1}^n$ where $y_i = f(t_i) + \epsilon_i$ on a uniform grid.
        \item Noise is assumed to be additive and Gaussian, $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$.
    \end{itemize}
    \item[Objective:]
    \begin{itemize}
        \item Estimate the $k$-th order derivative, $\hat{f}^{(k)}(t)$, for derivative orders $k \in \{0, 1, \ldots, 7\}$.
    \end{itemize}
    \item[Constraints:]
    \begin{itemize}
        \item The evaluation is performed on the interior of the domain to avoid boundary effects that can unfairly penalize certain methods.
        \item A method is considered to have failed a configuration if it does not produce a finite result.
    \end{itemize}
\end{description}

\subsection{Testbed: Dynamical Systems}
\label{sec:test_systems}

We selected three well-known Ordinary Differential Equation (ODE) systems to serve as the source of our ground-truth data. These systems were chosen to represent a diversity of dynamic behaviors:

\begin{enumerate}
    \item \textbf{Lotka-Volterra:} A classic two-variable system exhibiting stable periodic oscillations.
    \item \textbf{Van der Pol Oscillator:} A system with a non-linear damping term that produces a stable limit cycle.
    \item \textbf{Lorenz System:} A three-variable system famous for its chaotic behavior~\cite{Lorenz_1963}, providing a more challenging test case.
\end{enumerate}

For each system, trajectories were generated using a high-precision numerical integrator. The system's equations were then used to analytically compute the true derivatives up to the 7th order, providing a high-fidelity ground truth for our comparisons.

\subsection{Noise Model}
\label{sec:noise_model}

To simulate real-world data, we added Gaussian white noise to the integrated trajectories. The noise level was varied across a wide range, from \texttt{1e-8} (representing nearly clean data) up to \texttt{0.02} (representing a challenging 2\% noise level relative to the signal's standard deviation). This wide range allows us to evaluate method performance in both high-precision, low-noise regimes and robustness-critical, high-noise regimes.

\subsection{Evaluation Metrics}
\label{sec:metrics}

The primary metric for evaluation is the normalized Root-Mean-Square Error (nRMSE).

\textbf{Rationale for Normalization:} Direct comparison of raw RMSE values is not possible across different derivative orders because the magnitudes of the derivatives themselves vary dramatically. For instance, in the Lotka-Volterra system, the standard deviation of the true signal might be $\sim$0.2, while the standard deviation of its seventh derivative can be $\sim 10^5$.

To create a fair, order-comparable metric, we normalize the raw RMSE by the standard deviation of the true derivative signal. This yields a dimensionless error metric where an nRMSE of 0.1 consistently means a 10\% error relative to the signal's characteristic magnitude, regardless of the derivative order.

All metrics are computed after excluding the endpoints of the time series, as many methods exhibit boundary effects that can unfairly skew the results.

\subsection{Success Criteria}
\label{sec:success_criteria}

While the nRMSE provides a continuous measure of performance, it is also useful to define a threshold for what constitutes a "successful" or "acceptable" result. A method is considered successful for a given configuration if it achieves an nRMSE of less than 1.0, meaning its average error is smaller than the typical deviation of the true signal itself. An nRMSE greater than 1.0 indicates that the error is dominating the signal, and values greater than 10 are considered a catastrophic failure.

% ===== END INCLUDED FILE: sections/section4_design =====

\FloatBarrier

% ===== BEGIN INCLUDED FILE: sections/section5_analysis =====
\section{Results and Analysis}
\label{sec:results}

After a comprehensive evaluation across a range of methods, three distinct dynamical systems, and a sweep of noise levels, clear patterns emerge. Performance was analyzed in two regimes: a "low-noise" regime ($\le 0.1\%$ noise) where precision is paramount, and a "high-noise" regime (1-2\% noise) where robustness is key.

The table below summarizes the performance of contender methods that demonstrated full data coverage for derivative orders 1 through 5. Methods are sorted by their overall average rank, giving equal weight to performance in both low- and high-noise regimes. Averages are calculated over orders 1-5 (excluding order 0 function approximation, focusing on actual derivative estimation).

% AUTO-GENERATED by gemini-analysis/generate_exploratory_tables.py
% To regenerate: ./scripts/04_generate_tables.sh
% Alternative versions (orders 3, 7) available as tab_summary_order{3,7}.tex
% [TABLE INPUT REMOVED: ../build/tables/publication/tab_summary_order5.tex]

\textbf{Our principal findings are as follows:}

\begin{enumerate}
    \item \textbf{Gaussian Process Regression (GPR) is the most robust and accurate method overall.} The Julia GPR implementation (\texttt{GP-TaylorAD-Julia}) and the improved Python variants (\texttt{GP-RBF-*}) are the clear winners, consistently occupying the top ranks in both low and high-noise regimes.
    \item \textbf{The optimal method depends on the noise level and derivative order.} While GPR is the best all-arounder, splines like \texttt{Spline-Dierckx-5} offer excellent precision in low-noise environments, making them a top choice for cleaner data, particularly at modest derivative orders. In the high-noise regime, the filtering-based \texttt{Savitzky-Golay} provides a computationally cheap and highly effective alternative, ranking solidly in the top half of contenders.
    \item \textbf{Theoretical limits matter.} Many common low-degree spline methods are, by definition, incapable of representing high-order derivatives, limiting their applicability.
    \item \textbf{Dedicated packages offer convenient and robust options, but need a differentiation backend.}   Purpose built libraries are convenient, but our strongest results come from extending them with either analytic or auto-differentiated derivatives of smoothed data.  For this to work best, the library should ideally produce very smooth models, and either expose some of the model internals or be amenable to AD.

\end{enumerate}

These findings are illustrated in the accompanying visualizations.


[FIGURE REMOVED - Caption: \textbf{High-Noise Performance (2\% noise, 4th derivative). - Label: fig:high_noise_comp]



[FIGURE REMOVED - Caption: \textbf{Low-Noise Precision (1e-6 noise, 5th derivative). - Label: fig:low_noise_comp]



[FIGURE REMOVED - Caption: \textbf{Performance Degradation with Increasing Derivative Order (Orders 1-5). - Label: fig:heatmap]


\FloatBarrier
The subsequent subsections detail the methodology and analysis that support these conclusions, starting with an explanation of our ranking approach.

\subsection{Ranking Methodology}
To produce the final summary table, we followed a two-step ranking process:
\begin{enumerate}
    \item \textbf{Per-Cell Ranking}: For each individual experimental cell—defined by a unique combination of \texttt{(ODE\_system, noise\_level, derivative\_order)}—we ranked the contender methods against each other based on their mean \texttt{nRMSE} (averaged across the 10 trials for that cell).
    \item \textbf{Averaging Ranks}: We then calculated the final "Avg. Rank" for each method by averaging these per-cell ranks across two distinct regimes:
    \begin{itemize}
        \item \textbf{Low-Noise Regime}: Averaged across noise levels below 1\% (\texttt{1e-8}, \texttt{1e-6}, \texttt{1e-4}, and \texttt{1e-3}).
        \item \textbf{High-Noise Regime}: Averaged across noise levels of 1\% and above (\texttt{0.01} and \texttt{0.02}).
    \end{itemize}
\end{enumerate}
This methodology ensures that the final rank is a robust measure of a method's performance across a wide variety of conditions, and it prevents a single outlier or a particularly favorable test case from dominating the results.

\subsection{Performance Degradation by Derivative Order}
A clear pattern emerging from the data is the systematic degradation of performance as the derivative order increases. This is an expected consequence of the ill-posed nature of differentiation. We can characterize this trend in several phases:
\begin{itemize}
    \item \textbf{Orders 0-2 (Low-Order):} In this regime, most contender methods perform well, and the performance differences between them are relatively modest, particularly in low-noise scenarios. The task of smoothing or finding a first or second derivative is not challenging enough to create significant separation between the top methods.
    \item \textbf{Orders 3-5 (Mid-Order):} This is the regime where a clear separation emerges. The task becomes significantly more challenging, and methods without sophisticated noise handling begin to struggle. The performance of GPR and the stronger spectral methods remains high, while simpler spline- and filter-based methods see a substantial drop in accuracy.
    \item \textbf{Orders 6-7 (High-Order):} This regime represents an extreme challenge. Only a very small subset of methods, primarily GPR, are able to produce a usable estimate, and even their errors are significant. For most other methods, the error in this regime constitutes a catastrophic failure. Derivative order is clearly the dominant factor in the difficulty of the estimation problem.
\end{itemize}

Figure~\ref{fig:small_multiples} provides a comprehensive visual illustration of this systematic degradation. The figure shows performance across all eight derivative orders for the top seven methods, clearly demonstrating how error increases with order and how different methods respond to increasing noise levels at each order.


[FIGURE REMOVED - Caption: \textbf{Performance Across All Derivative Orders. - Label: fig:small_multiples]


\FloatBarrier
% Computational efficiency considerations moved to Practitioner's Guide in Conclusion
% Removed PyNumDiff analysis subsection - methods are included in main results

% ===== END INCLUDED FILE: sections/section5_analysis =====

\FloatBarrier

% ===== BEGIN INCLUDED FILE: sections/section6_conclusion =====
\section{Conclusion}
\label{sec:conclusion}

This comprehensive study evaluated a wide array of numerical methods for the estimation of high-order derivatives from noisy data. After a detailed investigation that included a multi-stage filtering of methods and a deep dive into implementation details, our findings are clear and decisive.

\subsection{Summary of Key Findings}

\begin{itemize}
    \item \textbf{Gaussian Process Regression (GPR) is the most robust and accurate method overall.} GPR methods consistently occupy the top ranks in both low- and high-noise regimes, making them the most reliable choice for general-purpose derivative estimation.
    \item \textbf{The optimal method depends on the use case.} While GPR is the best all-arounder, splines like \texttt{Spline-Dierckx-5} offer excellent precision for low-noise data, while spectral methods provide moderate accuracy at interactive speeds. For real-time applications requiring sub-10ms response, \texttt{Savitzky-Golay} remains the most practical choice despite lower accuracy.
    \item \textbf{Derivative order is the dominant difficulty factor.} Performance degrades systematically with increasing order across all methods. The problem becomes significantly more challenging beyond order 3, and only a handful of methods produce usable results at orders 6 or 7.
    \item \textbf{Implementation quality is a critical method characteristic.} Our study found significant performance differences between different software packages implementing the same underlying algorithm, highlighting that practitioners must consider the quality of a specific implementation, not just the theoretical method.
\end{itemize}

\textbf{The primary recommendation of this work is that for practitioners who require accurate high-order derivatives from real-world, noisy signals, Gaussian Process Regression is the most reliable and effective starting point.}

\subsection{Computational Cost and Method Selection}
\label{sec:practitioners_guide}

Computational costs vary significantly across methods, from milliseconds for filters to seconds for Gaussian Processes. The smoothing/fitting step dominates timing; derivative order has minimal impact on computational cost. Table~\ref{tab:timing} shows representative methods spanning the speed-accuracy spectrum.


[TABLE REMOVED - Caption: Computational Cost vs Accuracy Trade-Off - Label: tab:timing]


\textbf{Speed-Accuracy Tradeoff:}

Figure~\ref{fig:pareto} illustrates the speed-accuracy tradeoff at noise level 0.0001 and derivative order 3. Remarkably, only four methods define the Pareto frontier:
\begin{itemize}
    \item \texttt{SavitzkyGolay-Fixed} (1.1 ms): Fastest method on the frontier (nRMSE = 0.52)
    \item \texttt{ButterworthSpline\_Python} (4.0 ms): Fast filtering approach (nRMSE = 0.38)
    \item \texttt{Spline-Dierckx-5} (8.8 ms): High-degree spline interpolation (nRMSE = 0.32)
    \item \texttt{GP-TaylorAD-Julia} (1.78 s): Best accuracy, three orders of magnitude slower (nRMSE = 0.14)
\end{itemize}

The large gap between sub-millisecond filters and second-scale GP methods suggests an opportunity for methods that better balance speed and accuracy in the 10--100 ms range.


[FIGURE REMOVED - Caption: \textbf{Speed-accuracy tradeoff for derivative estimation methods. - Label: fig:pareto]


\FloatBarrier
\textbf{Practical Recommendations:}

When accuracy is paramount, \texttt{GP-TaylorAD-Julia} consistently delivers the best results across all derivative orders. For applications with timing constraints:

\begin{itemize}
    \item \textbf{Real-time (< 10 ms):} \texttt{SavitzkyGolay-Fixed}, \texttt{ButterworthSpline\_Python}, or \texttt{Spline-Dierckx-5} provide acceptable accuracy for orders 0--3.

    \item \textbf{Interactive (10--100 ms):} \texttt{Fourier-GCV} offers good accuracy/speed balance.

    \item \textbf{Offline analysis:} \texttt{GP-TaylorAD-Julia} (1.8 s) remains practical for batch processing.
\end{itemize}

Note that GP methods scale as $O(N^3)$ with data size, while spectral methods scale as $O(N \log N)$, making the latter preferable for very large datasets.

\subsection{Future Work}

This benchmark, while comprehensive, is not exhaustive. Several avenues for future research are immediately apparent:

\begin{enumerate}
    \item \textbf{Testing on Diverse Signals:} Our study used ODEs that produce smooth, analytic signals. Future work should include testing on more challenging signals, such as those with discontinuities, sharp peaks, or chaotic behavior.
    \item \textbf{Evaluating Alternative Noise Models:} The real world is not always Gaussian. A valuable extension would be to evaluate method performance under different noise models, such as multiplicative, Poisson, or heavy-tailed noise.
    \item \textbf{Larger-Scale Problems:} Our study was limited to a modest number of data points. Investigating how method performance, particularly computational cost, scales to much larger datasets ($N > 1000$) would be of great practical interest.
\end{enumerate}

\subsection{Broader Implications: The Case for a Composable, Differentiable Ecosystem}

Our findings also underscore a broader trend in scientific computing: the immense value of composable and differentiable software packages. The "Approximant-AD" framework is only possible when libraries for data modeling (e.g., Gaussian Processes) can seamlessly pass their results to libraries for automatic differentiation.

While not all numerical packages are readily differentiable out-of-the-box, our experience suggests that many can be adapted with modest effort. We encourage researchers and developers to prioritize differentiability in their own software and to contribute upstream to make foundational libraries in the ecosystem compatible with AD frameworks. Such efforts create a virtuous cycle, unlocking powerful new hybrid methodologies that benefit the entire scientific community, far beyond the immediate application of derivative estimation.

% ===== END INCLUDED FILE: sections/section6_conclusion =====

\FloatBarrier

%==============================================================================
% APPENDICES
%==============================================================================
\appendix

% ===== BEGIN INCLUDED FILE: sections/appendixA_method_catalog_complete =====
\section{Complete Method Catalog}
\label{sec:method_catalog_appendix}

This appendix provides comprehensive documentation for the 26 contender methods that demonstrated full coverage across derivative orders 0--5. Methods are organized by algorithmic family, with standardized naming conventions and complete implementation details.

\subsection{Method Summary Table}

Table~\ref{tab:method_catalog_complete} presents all contender methods with their key characteristics. Methods are grouped by algorithmic category to facilitate comparison within families.

\footnotesize
[LONGTABLE REMOVED]

\subsection{Implementation Details}

\subsubsection{Package Dependencies}

\textbf{Julia Packages:}
\begin{itemize}
    \item \texttt{GaussianProcesses.jl} (v0.12.5): GP-Julia-AD~\cite{Fairbrother_etal_2022}
    \item \texttt{TaylorDiff.jl} (v0.2.1): Taylor-mode AD for GP-Julia-AD, AAA methods~\cite{TaylorDiff_jl}
    \item \texttt{BaryRational.jl} (v0.3.0): AAA rational approximation~\cite{BaryRational_jl}
    \item \texttt{Dierckx.jl} (v0.5.2): Wrapper for FORTRAN FITPACK splines~\cite{Dierckx_jl, Dierckx_1993}
    \item \texttt{GeneralizedSmoothingSplines.jl} (v0.1.3): GSS implementation~\cite{Wahba_1990}
    \item \texttt{FFTW.jl} (v1.5.0): Fast Fourier transforms
    \item \texttt{SavitzkyGolay.jl} (v0.3.1): Savitzky-Golay filter implementations~\cite{Savitzky_Golay_1964}
    \item \texttt{Wavelets.jl} (v0.9.5): Wavelet transforms for noise estimation~\cite{Wavelets_jl}
\end{itemize}

\textbf{Python Packages:}
\begin{itemize}
    \item \texttt{scikit-learn} (1.3.0): Gaussian Process regression~\cite{Pedregosa_etal_2011}
    \item \texttt{numpy} (1.24.3): Core numerical operations, polynomial fitting~\cite{Harris_etal_2020}
    \item \texttt{scipy} (1.11.1): Signal processing, optimization~\cite{Virtanen_etal_2020}
    \item \texttt{PyNumDiff} (0.1.0): Comprehensive differentiation package~\cite{VanBreugel_etal_2022}
\end{itemize}

\subsubsection{Key Implementation Choices}

\textbf{Gaussian Process Methods:}
\begin{itemize}
    \item All use RBF (squared exponential) kernel: $k(x, x') = \sigma^2_f \exp(-\|x - x'\|^2 / 2\ell^2)$
    \item Hyperparameters ($\ell$, $\sigma_f$, $\sigma_n$) optimized via Maximum Likelihood Estimation
    \item Julia implementation uses Taylor-mode AD for efficient high-order derivatives
    \item Python implementation tested with isotropic/anisotropic kernels and mean subtraction preprocessing; all variants yielded identical performance
    \item Python implementations limited by lack of Taylor-mode AD (explains 10× speed difference)
\end{itemize}

\textbf{Spectral Methods:}
\begin{itemize}
    \item Differentiation via frequency domain: $\mathcal{F}\{f^{(n)}\}(k) = (ik)^n \mathcal{F}\{f\}(k)$
    \item Various strategies for frequency cutoff: fixed (40\%), adaptive (SNR-based), or GCV
    \item Fourier continuation methods use smooth extension to handle non-periodic data
    \item Chebyshev methods use domain scaling to $[-1, 1]$ before fitting
\end{itemize}

\textbf{Local Polynomial Methods:}
\begin{itemize}
    \item Savitzky-Golay filters use polynomial degree $d = \min(7, n + 2)$ for $n$-th derivative
    \item Window size selection: fixed ($w = n/4$) or adaptive based on noise estimation
    \item Boundary handling via asymmetric filters near endpoints
\end{itemize}

\textbf{Rational Approximation:}
\begin{itemize}
    \item AAA algorithm constructs barycentric rational interpolant: $r(z) = \sum_i w_i f_i / (z - z_i) / \sum_i w_i / (z - z_i)$
    \item Support points selected greedily based on maximum residual
    \item Tolerance setting critical: too tight causes overfitting, too loose underfits
    \item Known instability at high derivative orders despite mathematical correctness
\end{itemize}

\subsubsection{Computational Complexity Notes}

\begin{itemize}
    \item \textbf{$O(n)$ methods:} Savitzky-Golay filters, finite differences, splines (excluding GSS)
    \item \textbf{$O(n \log n)$ methods:} All Fourier/FFT-based spectral methods
    \item \textbf{$O(n^2)$ methods:} Chebyshev polynomials, AAA rational approximation, TV regularization
    \item \textbf{$O(n^3)$ methods:} Gaussian Processes (matrix inversion), GSS (dense linear systems)
\end{itemize}

The computational complexity is essentially independent of derivative order for all methods, as the dominant cost is in the smoothing/approximation step rather than the differentiation itself.

\subsection{Parameter Selection and Tuning}

\subsubsection{Adaptive Parameter Selection}

Several methods employ adaptive strategies to automatically select parameters based on data characteristics:

\textbf{Noise Estimation Methods:}
\begin{itemize}
    \item \textbf{Wavelet MAD:} $\hat{\sigma} = \text{MAD}(\text{HF}_{\text{wavelet}}) / 0.6745$ using Daubechies-4 wavelets~\cite{Donoho_Johnstone_1994}.
    \item \textbf{Second-order differences:} $\hat{\sigma} = \sqrt{\sum (y_{i+1} - 2y_i + y_{i-1})^2 / 6(n-2)}$~\cite{Gasser_etal_1986}.
\end{itemize}

\textbf{Model Selection Criteria:}
\begin{itemize}
    \item \textbf{AICc:} $n \log(\text{RSS}/n) + 2p + 2p(p+1)/(n-p-1)$ for $p$ parameters
    \item \textbf{GCV:} $n \cdot \text{RSS} / (n - \text{df})^2$ where df = effective degrees of freedom
    \item \textbf{MLE:} Maximum likelihood for GP hyperparameters via L-BFGS-B optimization
\end{itemize}

\subsubsection{Fixed Parameters}

Some methods use fixed parameters determined through preliminary experiments:
\begin{itemize}
    \item Fourier-Interp: 40\% frequency cutoff
    \item AAA-LowPrec: tolerance = $10^{-13}$
    \item Savitzky-Golay-Fixed: window = $n/4$
\end{itemize}

\subsection{Method Selection Guidelines}

Based on our comprehensive evaluation, we provide the following guidance for method selection:

\textbf{For highest accuracy (orders 0--5):}
\begin{itemize}
    \item \textbf{Low noise ($<$ 0.01\%):} Dierckx-5 or GP-Julia-AD
    \item \textbf{High noise ($\geq$ 1\%):} GP-Julia-AD consistently best
    \item \textbf{Unknown noise:} GP methods with automatic noise estimation
\end{itemize}

\textbf{For computational efficiency:}
\begin{itemize}
    \item \textbf{Real-time ($<$ 10ms):} Savitzky-Golay variants
    \item \textbf{Interactive ($<$ 100ms):} Spectral methods (Fourier-GCV, Chebyshev-AICc)
    \item \textbf{Batch processing:} GP-Julia-AD (2s) acceptable for highest accuracy
\end{itemize}

\textbf{For specific signal types:}
\begin{itemize}
    \item \textbf{Periodic/smooth:} Fourier methods excel
    \item \textbf{Non-periodic:} Fourier-Continuation or splines
    \item \textbf{Discontinuous:} TVRegDiff preserves edges (limited to order 1)
\end{itemize}

\textbf{Implementation recommendations:}
\begin{itemize}
    \item Compiled implementations generally faster than interpreted equivalents, and back-ends (for linear algebra, AD) matter
    \item Taylor-mode AD critical for efficient high-order derivatives
    \item Pre-compute smoothed approximant when multiple derivatives needed
\end{itemize}
% ===== END INCLUDED FILE: sections/appendixA_method_catalog_complete =====


% ===== BEGIN INCLUDED FILE: sections/appendixB_high_order =====
\section{High-Order Derivatives (Orders 6-7)}
\label{app:high_order}

High-order derivatives (6th and 7th order) present a particularly challenging test case for numerical differentiation methods. These orders are rarely required in practice but serve as a valuable stress test to understand method behavior at the limits of numerical stability.

\subsection{Challenges at High Orders}

Computing 6th and 7th order derivatives numerically is fundamentally difficult due to:

\begin{itemize}
    \item \textbf{Noise Amplification}: Each order of differentiation approximately multiplies the noise effect by a factor related to the inverse of the sampling interval, leading to exponential growth in uncertainty.
    \item \textbf{Numerical Precision}: Finite precision arithmetic introduces round-off errors that compound with each derivative order.
    \item \textbf{Method Limitations}: Many methods are theoretically limited to lower orders (e.g., low-degree polynomial approximations) or become numerically unstable at high orders.
\end{itemize}

As a result, only 24 out of 62 tested methods successfully produce valid predictions for both orders 6 and 7 across all test configurations.

\subsection{Performance Across Noise Regimes}

Figure~\ref{fig:high_order_heatmap} presents a three-panel comparison showing how the top 15 methods perform on orders 6-7 across different noise regimes. The panels reveal three key insights:

\begin{enumerate}
    \item \textbf{Overall Performance (All Noise Levels)}: Gaussian Process methods (\texttt{GP-TaylorAD-Julia} and \texttt{GP-RBF-Python}) substantially outperform all alternatives, achieving mean nRMSE $\approx 0.5$ compared to $\approx 0.9$ for the next-best Fourier methods.

    \item \textbf{Low-Noise Regime ($\le 0.1\%$)}: In clean data conditions, GP methods maintain excellent performance (nRMSE $\approx 0.32-0.34$), demonstrating their ability to extract high-order derivatives when signal quality permits. Savitzky-Golay variants emerge as the next-best alternatives (nRMSE $\approx 0.65-0.79$).

    \item \textbf{High-Noise Regime ($\ge 1\%$)}: At realistic noise levels, all methods struggle significantly. GP methods remain the most robust (nRMSE $\approx 0.88$), but even they approach the threshold of practical utility. Fourier methods show comparable robustness (nRMSE $\approx 0.95-0.97$), suggesting that frequency-domain approaches may be competitive when high precision is unattainable.
\end{enumerate}


[FIGURE REMOVED - Caption: \textbf{High-Order Derivatives (Orders 6-7) Performance Across Noise Regimes. - Label: fig:high_order_heatmap]


\FloatBarrier
\subsection{Practical Recommendations}

Based on this analysis, we offer the following guidance for practitioners needing high-order derivatives:

\begin{itemize}
    \item \textbf{First choice}: \texttt{GP-TaylorAD-Julia} provides the best performance across all noise regimes and is the recommended method when computational cost is acceptable.

    \item \textbf{Low-noise alternative}: In clean data environments ($< 0.1\%$ noise), \texttt{SavitzkyGolay-Adaptive} offers a computationally cheaper alternative with acceptable accuracy.

    \item \textbf{High-noise reality}: At noise levels $\ge 1\%$, computing reliable 6th and 7th order derivatives may be fundamentally impractical. Consider whether the application truly requires these high orders, or if lower-order approximations suffice.

    \item \textbf{Avoid high orders when possible}: The dramatic performance degradation at orders 6-7 (compared to orders 1-5 shown in Figure~\ref{fig:heatmap}) suggests that applications should avoid requiring these orders unless absolutely necessary.
\end{itemize}

\subsection{Comparison to Primary Results}

The methods ranked highly for orders 1-5 (Figure~\ref{fig:heatmap}) generally maintain their relative performance at orders 6-7, with one notable exception: Savitzky-Golay methods (both \texttt{SavitzkyGolay-Adaptive} and \texttt{SavitzkyGolay-Fixed}) move from mid-tier performers at low orders to being among the top alternatives to GP methods at high orders in low-noise conditions. This suggests that local polynomial fitting, while not optimal overall, has specific advantages for high-order differentiation when data quality is sufficient.

% ===== END INCLUDED FILE: sections/appendixB_high_order =====


%==============================================================================
% OLD PAPER STRUCTURE (DEPRECATED)
%==============================================================================
% \section{Related Work}
% \label{sec:related_work}
% \TODO{Related work section.}

% 
% ===== BEGIN INCLUDED FILE: sections/section3_problem =====
% [File not found: /home/orebas/tmp/deriv-estimation-study/report/sections/section3_problem.tex]
% ===== END INCLUDED FILE: sections/section3_problem =====

% 
% ===== BEGIN INCLUDED FILE: sections/section4_methodology =====
% [File not found: /home/orebas/tmp/deriv-estimation-study/report/sections/section4_methodology.tex]
% ===== END INCLUDED FILE: sections/section4_methodology =====

% 
% ===== BEGIN INCLUDED FILE: sections/section5_methods =====
% [File not found: /home/orebas/tmp/deriv-estimation-study/report/sections/section5_methods.tex]
% ===== END INCLUDED FILE: sections/section5_methods =====

% 
% ===== BEGIN INCLUDED FILE: sections/section6_results =====
% [File not found: /home/orebas/tmp/deriv-estimation-study/report/sections/section6_results.tex]
% ===== END INCLUDED FILE: sections/section6_results =====

% 
% ===== BEGIN INCLUDED FILE: sections/section7_discussion =====
% [File not found: /home/orebas/tmp/deriv-estimation-study/report/sections/section7_discussion.tex]
% ===== END INCLUDED FILE: sections/section7_discussion =====

% 
% ===== BEGIN INCLUDED FILE: sections/section8_recommendations =====
% [File not found: /home/orebas/tmp/deriv-estimation-study/report/sections/section8_recommendations.tex]
% ===== END INCLUDED FILE: sections/section8_recommendations =====

% 
% ===== BEGIN INCLUDED FILE: sections/section9_limitations =====
% [File not found: /home/orebas/tmp/deriv-estimation-study/report/sections/section9_limitations.tex]
% ===== END INCLUDED FILE: sections/section9_limitations =====

% 
% ===== BEGIN INCLUDED FILE: sections/section10_conclusion =====
% [File not found: /home/orebas/tmp/deriv-estimation-study/report/sections/section10_conclusion.tex]
% ===== END INCLUDED FILE: sections/section10_conclusion =====


%==============================================================================
% ACKNOWLEDGMENTS
%==============================================================================
\section*{Acknowledgments}
We thank the developers of GaussianProcesses.jl, Dierckx.jl, FFTW.jl, and scikit-learn for their open-source implementations.
% TODO: Add specific acknowledgments for funding, computational resources, reviewers

%==============================================================================
% BIBLIOGRAPHY
%==============================================================================
\bibliographystyle{plain}
\bibliography{references}
% TODO: Create references.bib file with all citations

%==============================================================================
% APPENDICES (Now correctly structured)
%==============================================================================
% \appendix % This is now at the top of the appendix section

\section{Detailed Results Tables}
\label{app:results}

This appendix contains detailed tables of the mean normalized Root-Mean-Square Error (nRMSE) for all contender methods across all noise levels, for each derivative order from 0 to 5. Each table shows performance across seven noise levels (1e-08 to 2e-02) with the mean across all noise levels in the final column.


[TABLE REMOVED - Caption: Derivative Order 0 (function approximation): Mean nRMSE across noise levels and methods. - Label: tab:order_0_results]



[TABLE REMOVED - Caption: Derivative Order 1 (first derivative): Mean nRMSE across noise levels and methods. - Label: tab:order_1_results]



[TABLE REMOVED - Caption: Derivative Order 2 (second derivative): Mean nRMSE across noise levels and methods. - Label: tab:order_2_results]



[TABLE REMOVED - Caption: Derivative Order 3 (third derivative): Mean nRMSE across noise levels and methods. - Label: tab:order_3_results]



[TABLE REMOVED - Caption: Derivative Order 4 (fourth derivative): Mean nRMSE across noise levels and methods. - Label: tab:order_4_results]



[TABLE REMOVED - Caption: Derivative Order 5 (fifth derivative): Mean nRMSE across noise levels and methods. - Label: tab:order_5_results]



% ===== BEGIN INCLUDED FILE: sections/appendixC_reproducibility =====
\section{Reproducibility}
\label{app:reproducibility}

This study was designed to be fully reproducible. All code, data, analysis scripts, and this manuscript's complete version history are available at the public Git repository: \url{https://github.com/orebas/deriv-estimation-study}.

\subsection{Software Environment}

The computational environment uses Julia 1.12.1 and Python 3.13.1. All package dependencies are managed by lock files (\texttt{uv.lock} for Python, \texttt{Manifest.toml} for Julia) to ensure exact package versions are preserved. A complete catalog of all methods and their dependencies is available in Appendix~\ref{sec:method_catalog_appendix}.

All sources of randomness are deterministically seeded to ensure identical datasets are generated on each run. Specifically:
\begin{itemize}
    \item Noise generation for each trial uses a fixed seed derived from the system name, noise level, and trial number
    \item ODE integration uses deterministic solvers with fixed tolerances
    \item Random parameter initializations (where applicable) use consistent seeds
\end{itemize}

\subsection{Computational Workflow}

The entire workflow, from running the comprehensive benchmark to generating all figures, tables, and this PDF, is fully automated. The main script \texttt{scripts/build\_all.sh} executes the complete pipeline in the following stages:

\begin{enumerate}
    \item \texttt{01\_run\_pilot.sh}: Quick validation test ($\sim$1 minute)
    \item \texttt{02\_run\_comprehensive.sh}: Full benchmark across all methods, systems, noise levels, and derivative orders ($\sim$7-10 minutes)
    \item \texttt{03\_generate\_figures.sh}: Generate all plots and visualizations ($\sim$30 seconds)
    \item \texttt{04\_generate\_tables.sh}: Generate LaTeX tables from results ($\sim$10 seconds)
    \item \texttt{05\_compile\_paper.sh}: Compile this manuscript ($\sim$20 seconds)
\end{enumerate}

All intermediate results are stored in the \texttt{build/} directory with timestamps, allowing verification of the complete data pipeline.

\subsection{Hardware Specifications}

All benchmarks were run on an AMD Ryzen 7 2700 Eight-Core Processor with 64 GB RAM, running Ubuntu 24.04.3 LTS under WSL2.

\subsection{Data Availability}

The complete dataset including:
\begin{itemize}
    \item Raw prediction outputs for all 28 methods across all test configurations
    \item Aggregated summary statistics (\texttt{comprehensive\_summary.csv})
    \item All generated figures in publication-quality format
    \item LaTeX table sources
\end{itemize}
is preserved in the \texttt{build/results/} directory and available in the repository.

% ===== END INCLUDED FILE: sections/appendixC_reproducibility =====


\end{document}
